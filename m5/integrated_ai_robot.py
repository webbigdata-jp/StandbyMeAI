import asyncio
import json
import numpy as np
import webrtcvad
import requests
import io
import wave
import httpx
import re
import torch
from snac import SNAC
import pyaudio
import threading
import queue
import time
import websockets
import serial
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from transformers import AutoTokenizer
import logging


"""
build\bin\llama-server -hf unsloth/gemma-3n-E2B-it-GGUF:gemma-3n-E2B-it-UD-Q4_K_XL.gguf --prio 3 -c 2048 -e -n -2 -ngl 99 --port 8080 --host 0.0.0.0 --no-webui -v --cont-batching

.\build\bin\whisper-server.exe -m models/ggml-kotoba-whisper-v2.0.bin --host 0.0.0.0 --port 8082 -l ja --print-colors

build\bin\llama-server -hf webbigdata/VoiceCore_gguf:VoiceCore-Q4_K-f16.gguf --prio 3 -c 2048 -e -n -2 --port 8081 --host 0.0.0.0 -ngl 99 --no-webui -v --cont-batching
"""


# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class IntegratedVoiceChatSystem:
    def __init__(self, serial_port='COM3'):
        # ã‚µãƒ¼ãƒãƒ¼URLè¨­å®š
        self.whisper_url = "http://localhost:8082"
        self.gemma_url = "http://localhost:8080"
        self.voicecore_url = "http://localhost:8081"
        
        # ã‚·ãƒªã‚¢ãƒ«é€šä¿¡è¨­å®šï¼ˆAtomS3åˆ¶å¾¡ï¼‰
        self.serial_port = serial_port
        self.serial_connection = None
        self._init_serial()
        
        # éŸ³å£°è¨­å®š
        self.sample_rate = 16000
        self.frame_duration = 30  # ms
        self.frame_size = int(self.sample_rate * self.frame_duration / 1000)
        
        # VADè¨­å®š
        self.vad = webrtcvad.Vad(2)
        self.MIN_AUDIO_LENGTH = 0.5
        self.SILENCE_THRESHOLD = 30
        self.VOLUME_THRESHOLD = 0.01
        
        # VADç„¡åŠ¹åŒ–åˆ¶å¾¡ï¼ˆPCéŸ³å£°å†ç”Ÿä¸­ã®èª¤èªè­˜é˜²æ­¢ï¼‰
        self.is_vad_enabled = True
        self.vad_disable_start_time = None
        
        # éŸ³å£°å†ç”Ÿè¨­å®š
        self.audio_queue = queue.Queue()
        self.is_playing = False
        self.playback_thread = None
        self.playback_sample_rate = 24000
        
        # ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°åˆ¶å¾¡
        self.initial_buffer = []  # åˆå›ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç”¨
        self.is_initial_buffering = True
        self.buffer_start_time = None
        
        # AIè¨­å®š
        self.system_prompt = "ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç°¡æ½”ã«1æ–‡ã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚"
        self.conversation_history = []
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.snac_model = None
        self.tokenizer = None
        self._load_models()
    
    def _init_serial(self):
        """AtomS3ã‚·ãƒªã‚¢ãƒ«æ¥ç¶šåˆæœŸåŒ–"""
        try:
            self.serial_connection = serial.Serial(self.serial_port, 115200, timeout=1)
            logger.info(f"AtomS3æ¥ç¶šæˆåŠŸ: {self.serial_port}")
            time.sleep(2)  # æ¥ç¶šå®‰å®šåŒ–å¾…æ©Ÿ
        except serial.SerialException as e:
            logger.warning(f"AtomS3æ¥ç¶šå¤±æ•—: {e}")
            self.serial_connection = None
    
    def send_emotion_command(self, emotion):
        """AtomS3ã«æ„Ÿæƒ…ã‚³ãƒãƒ³ãƒ‰é€ä¿¡ï¼ˆæ”¹è¡Œã‚³ãƒ¼ãƒ‰ä»˜ãï¼‰"""
        if not self.serial_connection or not self.serial_connection.is_open:
            logger.warning("AtomS3ãŒæ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        try:
            command_map = {
                'smile': 's',
                'cry': 'c'
            }
            
            if emotion in command_map:
                command = command_map[emotion]
                # æ”¹è¡Œã‚³ãƒ¼ãƒ‰ä»˜ãã§é€ä¿¡ï¼ˆAtomS3ã®readline()å¯¾å¿œï¼‰
                self.serial_connection.write(f'{command}\n'.encode('utf-8'))
                logger.info(f"AtomS3ã«é€ä¿¡: '{command}\\n'")
            else:
                logger.debug(f"ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ„Ÿæƒ…ã®ãŸã‚é€ä¿¡ãªã—: {emotion}")
        except Exception as e:
            logger.error(f"AtomS3ã‚³ãƒãƒ³ãƒ‰é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
    
    def analyze_emotion_from_text(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ„Ÿæƒ…åˆ†æ"""
        text_lower = text.lower()
        
        # å–œã³ãƒ»æŒ¨æ‹¶ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        smile_keywords = [
            'ã“ã‚“ã«ã¡ã¯', 'ãŠã¯ã‚ˆã†', 'ã“ã‚“ã°ã‚“ã¯', 'ã‚ã‚ŠãŒã¨ã†', 'ã†ã‚Œã—ã„', 
            'å¬‰ã—ã„', 'æ¥½ã—ã„', 'è‰¯ã„', 'ã„ã„', 'ç´ æ™´ã‚‰ã—ã„', 'æœ€é«˜', 'ã‚ˆã‹ã£ãŸ',
            'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™', 'ãŠã‚ã§ã¨ã†', 'å–œã³', 'å¹¸ã›', 'happy'
        ]
        
        # æ‚²ã—ã¿ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰  
        cry_keywords = [
            'æ‚²ã—ã„', 'ã‹ãªã—ã„', 'ã¤ã‚‰ã„', 'è¾›ã„', 'æ®‹å¿µ', 'å›°ã£ãŸ', 
            'å¿ƒé…', 'ã ã‚', 'ãƒ€ãƒ¡', 'å¤±æ•—', 'å«Œ', 'ã„ã‚„', 'æœ€æ‚ª',
            'ãŒã£ã‹ã‚Š', 'ã‚·ãƒ§ãƒƒã‚¯', 'æ³£ã', 'æ¶™', 'sad', 'sorry'
        ]
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        for keyword in smile_keywords:
            if keyword in text_lower:
                return 'smile'
        
        for keyword in cry_keywords:
            if keyword in text_lower:
                return 'cry'
        
        return 'neutral'
    
    def _load_models(self):
        """SNACãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã¿"""
        logger.info("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        try:
            self.snac_model = SNAC.from_pretrained("hubertsiuzdak/snac_24khz")
            self.snac_model.to("cpu")
            self.tokenizer = AutoTokenizer.from_pretrained("unsloth/gemma-3n-E2B-it")
            logger.info("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def is_speech(self, audio_frame):
        """VADã§éŸ³å£°åˆ¤å®šï¼ˆPCéŸ³å£°å†ç”Ÿä¸­ã¯ç„¡åŠ¹åŒ–ï¼‰"""
        # VADãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å¸¸ã«False
        if not self.is_vad_enabled:
            return False
        
        # VADç„¡åŠ¹åŒ–æœŸé–“ã‚’ãƒã‚§ãƒƒã‚¯
        if self.vad_disable_start_time is not None:
            elapsed_time = time.time() - self.vad_disable_start_time
            if elapsed_time < 8.0:  # 8ç§’é–“VADç„¡åŠ¹
                return False
            else:
                # 8ç§’çµŒéã—ãŸã‚‰VADå†æœ‰åŠ¹åŒ–
                self.vad_disable_start_time = None
                self.is_vad_enabled = True
                logger.info("ğŸ¤ VADå†æœ‰åŠ¹åŒ– - éŸ³å£°å…¥åŠ›å—ä»˜å†é–‹")
        
        try:
            rms = np.sqrt(np.mean(audio_frame ** 2))
            if rms < self.VOLUME_THRESHOLD:
                return False
            
            audio_int16 = (audio_frame * 32767).astype(np.int16)
            return self.vad.is_speech(audio_int16.tobytes(), self.sample_rate)
        except:
            return False
    
    def disable_vad_temporarily(self):
        """VADã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼ˆPCéŸ³å£°å†ç”Ÿé–‹å§‹æ™‚ã«å‘¼ã³å‡ºã—ï¼‰"""
        self.is_vad_enabled = False
        self.vad_disable_start_time = time.time()
        logger.info("ğŸ”‡ VADç„¡åŠ¹åŒ– - PCéŸ³å£°å†ç”Ÿä¸­ï¼ˆ8ç§’é–“ï¼‰")
    
    def _audio_to_wav_bytes(self, audio_data):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’WAVãƒã‚¤ãƒˆã«å¤‰æ›"""
        if np.max(np.abs(audio_data)) > 0:
            audio_data = audio_data / np.max(np.abs(audio_data)) * 0.9
        
        audio_int16 = (audio_data * 32767).astype(np.int16)
        wav_buffer = io.BytesIO()
        
        with wave.open(wav_buffer, 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(16000)
            wav_file.writeframes(audio_int16.tobytes())
        
        return wav_buffer.getvalue()
    
    async def transcribe(self, audio_data):
        """Whisperã§éŸ³å£°ã‚’æ–‡å­—ã«å¤‰æ›"""
        try:
            wav_bytes = self._audio_to_wav_bytes(audio_data)
            
            files = {'file': ('audio.wav', wav_bytes, 'audio/wav')}
            data = {
                'language': 'ja',
                'temperature': '0.0',
                'response_format': 'json'
            }
            
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: requests.post(f"{self.whisper_url}/inference", files=files, data=data, timeout=30)
            )
            
            if response.status_code == 200:
                result = response.json()
                text = result.get('text', '').strip()
                return text if text else None
            
        except Exception as e:
            logger.error(f"è»¢å†™ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    def _format_chat_prompt(self, user_input):
        """Gemma3Nç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        messages = [{"role": "system", "content": self.system_prompt}]
        messages.extend(self.conversation_history)
        messages.append({"role": "user", "content": user_input})
        
        prompt = ""
        for i, msg in enumerate(messages):
            is_last = (i == len(messages) - 1)
            if msg["role"] in ["user", "system"]:
                prompt += f"<start_of_turn>user\n{msg['content']}<end_of_turn>\n"
                if is_last:
                    prompt += "<start_of_turn>model\n"
            elif msg["role"] == "assistant":
                prompt += f"<start_of_turn>model\n{msg['content']}"
                if not is_last:
                    prompt += "<end_of_turn>\n"
        
        return prompt
    
    async def chat_with_gemma(self, user_input):
        """Gemma3Nã§å¿œç­”ç”Ÿæˆ"""
        try:
            prompt = self._format_chat_prompt(user_input)
            
            payload = {
                "prompt": prompt,
                "temperature": 1.0,
                "top_k": 64,
                "top_p": 0.95,
                "n_predict": 512,
                "stop": ["<end_of_turn>", "<|end_of_text|>"]
            }
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(f"{self.gemma_url}/completion", json=payload)
                
                if response.status_code == 200:
                    result = response.json()
                    content = result.get('content', '').strip()
                    
                    # å±¥æ­´æ›´æ–°
                    self.conversation_history.append({"role": "user", "content": user_input})
                    self.conversation_history.append({"role": "assistant", "content": content})
                    
                    # å±¥æ­´åˆ¶é™
                    if len(self.conversation_history) > 10:
                        self.conversation_history = self.conversation_history[-10:]
                    
                    return content
        except Exception as e:
            logger.error(f"Gemmaã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    def _redistribute_codes(self, tokens):
        """SNACã‚³ãƒ¼ãƒ‰å½¢å¼ã«å¤‰æ›"""
        code_list = [t - 128266 for t in tokens]
        layer_1, layer_2, layer_3 = [], [], []
        
        for i in range(len(code_list) // 7):
            layer_1.append(code_list[7*i])
            layer_2.append(code_list[7*i+1]-4096)
            layer_3.append(code_list[7*i+2]-(2*4096))
            layer_3.append(code_list[7*i+3]-(3*4096))
            layer_2.append(code_list[7*i+4]-(4*4096))
            layer_3.append(code_list[7*i+5]-(5*4096))
            layer_3.append(code_list[7*i+6]-(6*4096))
        
        return [
            torch.tensor(layer_1).unsqueeze(0),
            torch.tensor(layer_2).unsqueeze(0),
            torch.tensor(layer_3).unsqueeze(0)
        ]
    
    def snac_decode_to_audio(self, tokens):
        """SNACã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›"""
        if not tokens:
            return None
        
        code_length = (len(tokens) // 7) * 7
        if code_length == 0:
            return None
        
        tokens = tokens[:code_length]
        codes = self._redistribute_codes(tokens)
        
        with torch.inference_mode():
            audio_hat = self.snac_model.decode(codes)
            return audio_hat.detach().squeeze().cpu().numpy()
    
    async def generate_voice_tokens_streaming(self, text, callback=None):
        """
        VoiceCoreã§éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ
        70ãƒˆãƒ¼ã‚¯ãƒ³æ¯ã«ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‘¼ã³å‡ºã—ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†å®Œå…¨ç‰ˆï¼‰
        """
        voice_prompt = f"<custom_token_3><|begin_of_text|>amitaro_female[neutral]: {text}<|eot_id|><custom_token_4><custom_token_5><custom_token_1>"
        
        payload = {
            "prompt": voice_prompt,
            "temperature": 0.8,
            "top_p": 0.95,
            "n_predict": 2048,
            "repeat_penalty": 1.1,
            "repeat_last_n": 70,
            "stream": True  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æœ‰åŠ¹
        }
        
        collected_tokens = []
        all_tokens = []
        
        try:
            async with httpx.AsyncClient(timeout=None) as client:
                async with client.stream(
                    'POST',
                    f"{self.voicecore_url}/completion",
                    json=payload,
                    headers={"Accept": "text/event-stream"}
                ) as response:
                    
                    logger.info(f"ğŸ“¡ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¥ç¶šç¢ºç«‹: {response.status_code}")
                    
                    async for line in response.aiter_lines():
                        if line.strip():
                            # SSEãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤å»
                            if line.startswith("data: "):
                                line = line[6:]
                            
                            try:
                                data = json.loads(line)
                                
                                # ãƒˆãƒ¼ã‚¯ãƒ³æŠ½å‡º
                                if "content" in data:
                                    matches = re.findall(r'<custom_token_(\d+)>', data["content"])
                                    for match in matches:
                                        token_id = 128256 + int(match)
                                        collected_tokens.append(token_id)
                                        all_tokens.append(token_id)
                                        
                                        if len(collected_tokens) % 10 == 0:
                                            logger.debug(f"ğŸ¯ ãƒˆãƒ¼ã‚¯ãƒ³å—ä¿¡ä¸­: {len(collected_tokens)}")
                                        
                                        # 70ãƒˆãƒ¼ã‚¯ãƒ³æ¯ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
                                        if len(collected_tokens) >= 70:
                                            processable_count = (len(collected_tokens) // 7) * 7
                                            if processable_count > 0:
                                                tokens_to_process = collected_tokens[:processable_count]
                                                remaining_tokens = collected_tokens[processable_count:]
                                                
                                                logger.info(f"ğŸ¯ 70ãƒˆãƒ¼ã‚¯ãƒ³åˆ°é”! ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†: {len(tokens_to_process)}ãƒˆãƒ¼ã‚¯ãƒ³")
                                                if callback:
                                                    await callback(tokens_to_process)
                                                
                                                collected_tokens = remaining_tokens
                                
                                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµ‚äº†åˆ¤å®š
                                if data.get("stop", False):
                                    logger.info("ğŸ“ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµ‚äº†")
                                    break
                                    
                            except json.JSONDecodeError:
                                continue
                            except Exception as e:
                                logger.error(f"âŒ ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                                continue
                
                # æ®‹ã‚Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡¦ç†
                if collected_tokens:
                    processable_count = (len(collected_tokens) // 7) * 7
                    if processable_count > 0:
                        tokens_to_process = collected_tokens[:processable_count]
                        logger.info(f"ğŸ“¦ æœ€çµ‚ãƒãƒƒãƒå‡¦ç†: {len(tokens_to_process)}ãƒˆãƒ¼ã‚¯ãƒ³")
                        if callback:
                            await callback(tokens_to_process)
            
            logger.info(f"âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº† - ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(all_tokens)}")
            return all_tokens
            
        except Exception as e:
            logger.error(f"âŒ VoiceCoreã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def start_playback(self):
        """éŸ³å£°å†ç”Ÿé–‹å§‹"""
        if self.playback_thread is None or not self.playback_thread.is_alive():
            self.is_playing = True
            while not self.audio_queue.empty():
                try:
                    self.audio_queue.get_nowait()
                except:
                    break
            self.playback_thread = threading.Thread(target=self._playback_worker, daemon=True)
            self.playback_thread.start()
    
    def stop_playback(self):
        """éŸ³å£°å†ç”Ÿåœæ­¢"""
        self.is_playing = False
        self.audio_queue.put(None)
        if self.playback_thread and self.playback_thread.is_alive():
            self.playback_thread.join(timeout=1.0)
    
    def _playback_worker(self):
        """éŸ³å£°å†ç”Ÿãƒ¯ãƒ¼ã‚«ãƒ¼"""
        try:
            p = pyaudio.PyAudio()
            stream = p.open(
                format=pyaudio.paFloat32,
                channels=1,
                rate=self.playback_sample_rate,
                output=True,
                frames_per_buffer=2048
            )
            
            while self.is_playing:
                try:
                    audio_data = self.audio_queue.get(timeout=1.0)
                    if audio_data is None:
                        break
                    
                    if np.max(np.abs(audio_data)) > 0:
                        audio_data = audio_data / np.max(np.abs(audio_data)) * 0.8
                    
                    stream.write(audio_data.astype(np.float32).tobytes())
                    self.audio_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            
        except Exception as e:
            logger.error(f"å†ç”Ÿãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _streaming_audio_callback(self, tokens):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ï¼ˆåˆå›ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å¯¾å¿œï¼‰"""
        try:
            logger.debug(f"ğŸ”„ éŸ³å£°å¤‰æ›é–‹å§‹: {len(tokens)}ãƒˆãƒ¼ã‚¯ãƒ³")
            audio_data = self.snac_decode_to_audio(tokens)
            if audio_data is not None:
                logger.debug(f"âœ… éŸ³å£°å¤‰æ›å®Œäº†: {len(audio_data)}ã‚µãƒ³ãƒ—ãƒ«")
                
                if self.is_initial_buffering:
                    # åˆå›ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ä¸­ã¯é…åˆ—ã«è“„ç©
                    self.initial_buffer.append(audio_data)
                    
                    if self.buffer_start_time is None:
                        self.buffer_start_time = time.time()
                    
                    # 2.5ç§’çµŒéã—ãŸã‚‰åˆå›ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°çµ‚äº†
                    if time.time() - self.buffer_start_time >= 2.5:
                        logger.info("ğŸµ åˆå›ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å®Œäº† - å†ç”Ÿé–‹å§‹")
                        self.is_initial_buffering = False
                        
                        # å†ç”Ÿã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
                        self.start_playback()
                        
                        # è“„ç©ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ã¦ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                        for buffered_audio in self.initial_buffer:
                            self.audio_queue.put(buffered_audio)
                        
                        logger.info(f"ğŸ“¨ åˆå›ãƒãƒƒãƒ•ã‚¡ {len(self.initial_buffer)}ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ")
                        self.initial_buffer = []  # ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢
                else:
                    # é€šå¸¸æ™‚ã¯ç›´æ¥ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                    self.audio_queue.put(audio_data)
                    logger.debug(f"ğŸ“¨ éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ  - ã‚µã‚¤ã‚º: {self.audio_queue.qsize()}")
                    # 1ç§’é–“éš”
                    await asyncio.sleep(1.0)
            else:
                logger.warning(f"âŒ éŸ³å£°å¤‰æ›å¤±æ•—: ãƒˆãƒ¼ã‚¯ãƒ³æ•°={len(tokens)}")
        except Exception as e:
            logger.error(f"âŒ éŸ³å£°å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def process_conversation(self, text, websocket=None):
        """éŸ³å£°å¯¾è©±å‡¦ç†ã®å…¨ä½“ãƒ•ãƒ­ãƒ¼ï¼ˆVADåˆ¶å¾¡ä»˜ãï¼‰"""
        logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {text}")
        
        # 1. Gemmaã§å¿œç­”ç”Ÿæˆ
        response = await self.chat_with_gemma(text)
        if not response:
            return
        
        logger.info(f"å¿œç­”: {response}")
        
        # 2. æ„Ÿæƒ…åˆ†æã¨AtomS3åˆ¶å¾¡
        emotion = self.analyze_emotion_from_text(response)
        logger.info(f"æ„Ÿæƒ…åˆ†æçµæœ: {emotion}")
        self.send_emotion_command(emotion)
        
        # 3. WebSocketã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æ„Ÿæƒ…æƒ…å ±é€ä¿¡
        if websocket:
            await websocket.send_json({
                "type": "emotion_detected", 
                "emotion": emotion
            })
        
        # 4. VADç„¡åŠ¹åŒ–ï¼ˆPCéŸ³å£°å†ç”Ÿã®èª¤èªè­˜é˜²æ­¢ï¼‰
        self.disable_vad_temporarily()
        
        # 5. ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        self.is_initial_buffering = True
        self.initial_buffer = []
        self.buffer_start_time = None
        self.is_playing = False
        
        # ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        while not self.audio_queue.empty():
            try:
                self.audio_queue.get_nowait()
            except:
                break
        
        # 6. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ç”Ÿæˆé–‹å§‹
        logger.info("ğŸµ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ç”Ÿæˆé–‹å§‹ï¼ˆåˆå›2.5ç§’ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ï¼‰")
        
        try:
            # VoiceCoreã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ
            all_tokens = await self.generate_voice_tokens_streaming(
                response, 
                callback=self._streaming_audio_callback
            )
            
            logger.info(f"ğŸ“Š ç·éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(all_tokens)}")
            
            # ã¾ã ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ä¸­ã®å ´åˆã¯å¼·åˆ¶çš„ã«å†ç”Ÿé–‹å§‹
            if self.is_initial_buffering and self.initial_buffer:
                logger.info("ğŸµ ç”Ÿæˆå®Œäº† - æ®‹ã‚Šãƒãƒƒãƒ•ã‚¡ã‚’å†ç”Ÿé–‹å§‹")
                self.is_initial_buffering = False
                self.start_playback()
                
                for buffered_audio in self.initial_buffer:
                    self.audio_queue.put(buffered_audio)
                logger.info(f"ğŸ“¨ æœ€çµ‚ãƒãƒƒãƒ•ã‚¡ {len(self.initial_buffer)}ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ")
                self.initial_buffer = []
            
            # éŸ³å£°å†ç”Ÿå®Œäº†ã¾ã§å¾…æ©Ÿ
            estimated_duration = (len(all_tokens) // 70) * 1.0 + 5.0
            logger.info(f"â³ æ¨å®šç·å†ç”Ÿæ™‚é–“: {estimated_duration:.1f}ç§’")
            
            start_wait = time.time()
            while not self.audio_queue.empty():
                await asyncio.sleep(0.2)
                if time.time() - start_wait > estimated_duration:
                    logger.warning("âš ï¸ å†ç”Ÿã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                    break
            
            await asyncio.sleep(0.5)
            logger.info("ğŸµ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°å†ç”Ÿå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            logger.info("ğŸ›‘ éŸ³å£°å†ç”Ÿåœæ­¢")
            self.stop_playback()
            # VADã¯è‡ªå‹•çš„ã«8ç§’å¾Œã«å†æœ‰åŠ¹åŒ–ã•ã‚Œã‚‹
            logger.debug("æ„Ÿæƒ…è¡¨ç¤ºç¶™ç¶š")
    
    def close_serial(self):
        """ã‚·ãƒªã‚¢ãƒ«æ¥ç¶šã‚’é–‰ã˜ã‚‹"""
        if self.serial_connection and self.serial_connection.is_open:
            self.serial_connection.close()
            logger.info("AtomS3æ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸ")

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = FastAPI()
voice_system = IntegratedVoiceChatSystem()

@app.on_event("shutdown")
def shutdown_event():
    """ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã«ã‚·ãƒªã‚¢ãƒ«æ¥ç¶šã‚’é–‰ã˜ã‚‹"""
    voice_system.close_serial()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    logger.info("WebSocketæ¥ç¶šç¢ºç«‹")
    
    is_recording = False
    audio_buffer = []
    silence_counter = 0
    
    try:
        while True:
            data = await websocket.receive_bytes()
            audio_data = np.frombuffer(data, dtype=np.float32)
            
            if len(audio_data) >= voice_system.frame_size:
                frame = audio_data[:voice_system.frame_size]
                is_speech = voice_system.is_speech(frame)
                
                if is_speech:
                    if not is_recording:
                        is_recording = True
                        audio_buffer = []
                        logger.info("éŸ³å£°æ¤œå‡ºé–‹å§‹")
                        await websocket.send_json({"type": "speech_started"})
                    
                    audio_buffer.extend(audio_data)
                    silence_counter = 0
                else:
                    if is_recording:
                        audio_buffer.extend(audio_data)
                        silence_counter += 1
                        
                        if silence_counter >= voice_system.SILENCE_THRESHOLD:
                            audio_array = np.array(audio_buffer, dtype=np.float32)
                            duration = len(audio_array) / voice_system.sample_rate
                            
                            if duration >= voice_system.MIN_AUDIO_LENGTH:
                                logger.info(f"è»¢å†™é–‹å§‹: {duration:.1f}ç§’")
                                await websocket.send_json({"type": "processing"})
                                
                                # è»¢å†™
                                text = await voice_system.transcribe(audio_array)
                                if text:
                                    logger.info(f"è»¢å†™çµæœ: {text}")
                                    await websocket.send_json({
                                        "type": "transcription",
                                        "text": text
                                    })
                                    
                                    # éŸ³å£°å¯¾è©±å‡¦ç†
                                    await voice_system.process_conversation(text, websocket)
                                    
                                    await websocket.send_json({
                                        "type": "response_complete"
                                    })
                            
                            is_recording = False
                            audio_buffer = []
                            silence_counter = 0
                            await websocket.send_json({"type": "speech_ended"})
    
    except WebSocketDisconnect:
        logger.info("WebSocketåˆ‡æ–­")
    except Exception as e:
        logger.error(f"WebSocketã‚¨ãƒ©ãƒ¼: {e}")

@app.get("/")
async def root():
    return {"message": "çµ±åˆéŸ³å£°å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­"}

@app.get("/health")
async def health():
    return {"status": "healthy"}

# éŸ³å£°éŒ²éŸ³ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚·ãƒªã‚¢ãƒ«é€šä¿¡ãªã—ï¼‰
class VoiceClient:
    def __init__(self, server_url="ws://localhost:8003/ws"):
        self.server_url = server_url
        self.sample_rate = 16000
        self.chunk_size = 1024
        self.audio = pyaudio.PyAudio()
        # Clientã¯AtomS3ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ãªã„
        
    async def start_recording(self):
        """éŸ³å£°éŒ²éŸ³ã¨WebSocketé€ä¿¡ï¼ˆæ¥ç¶šå®‰å®šåŒ–ç‰ˆï¼‰"""
        import websockets
        from websockets.exceptions import ConnectionClosed, ConnectionClosedError
        
        # ãƒã‚¤ã‚¯è¨­å®š
        stream = self.audio.open(
            format=pyaudio.paFloat32,
            channels=1,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )
        
        print("ğŸ¤ éŸ³å£°éŒ²éŸ³é–‹å§‹ï¼è©±ã—ã¦ãã ã•ã„...")
        print("Ctrl+Cã§çµ‚äº†")
        
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # WebSocketæ¥ç¶šè¨­å®šï¼ˆå¤§å¹…ãªå®‰å®šåŒ–ï¼‰
                async with websockets.connect(
                    self.server_url,
                    ping_interval=None,   # pingã‚’ç„¡åŠ¹åŒ–ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåŸå› ï¼‰
                    ping_timeout=None,    # pingã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ç„¡åŠ¹åŒ–
                    close_timeout=10,     # æ¥ç¶šçµ‚äº†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå»¶é•·
                    max_size=2**20,      # æœ€å¤§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’1MB
                    max_queue=32         # ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºåˆ¶é™
                ) as websocket:
                    
                    print(f"âœ… ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã¾ã—ãŸ (è©¦è¡Œ {retry_count + 1}/{max_retries})")
                    retry_count = 0  # æ¥ç¶šæˆåŠŸã—ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
                    
                    while True:
                        try:
                            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
                            audio_data = stream.read(self.chunk_size, exception_on_overflow=False)
                            
                            # WebSocketã§é€ä¿¡
                            await websocket.send(audio_data)
                            
                            # ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”å—ä¿¡ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·ï¼‰
                            try:
                                response = await asyncio.wait_for(websocket.recv(), timeout=0.1)
                                message = json.loads(response)
                                
                                if message["type"] == "speech_started":
                                    print("ğŸ¯ éŸ³å£°æ¤œå‡º...")
                                elif message["type"] == "processing":
                                    print("ğŸ”„ å‡¦ç†ä¸­...")
                                elif message["type"] == "transcription":
                                    print(f"ğŸ“ èªè­˜: {message['text']}")
                                elif message["type"] == "emotion_detected":
                                    print(f"ğŸ˜Š æ„Ÿæƒ…: {message['emotion']}")
                                elif message["type"] == "response_complete":
                                    print("âœ… å¿œç­”å®Œäº†\n")
                            except asyncio.TimeoutError:
                                pass  # å¿œç­”ãªã—ï¼ˆæ­£å¸¸ï¼‰
                            
                            await asyncio.sleep(0.02)  # å°‘ã—é•·ã‚ã«
                        
                        except (ConnectionClosed, ConnectionClosedError) as e:
                            print(f"âš ï¸ WebSocketæ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸ: {e}")
                            break  # å†…å´ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦å†æ¥ç¶š
                        
                        except Exception as e:
                            print(f"âš ï¸ éŸ³å£°é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
                            await asyncio.sleep(0.1)
                            continue
                            
            except KeyboardInterrupt:
                print("\nğŸ›‘ éŒ²éŸ³çµ‚äº†")
                break
            
            except (ConnectionClosed, ConnectionClosedError, OSError) as e:
                retry_count += 1
                print(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {retry_count}/{max_retries}): {e}")
                
                if retry_count < max_retries:
                    print(f"ğŸ”„ {retry_count * 3}ç§’å¾Œã«å†æ¥ç¶šã‚’è©¦è¡Œ...")
                    await asyncio.sleep(retry_count * 3)  # ã‚ˆã‚Šé•·ã„å¾…æ©Ÿæ™‚é–“
                else:
                    print("âŒ æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    break
            
            except Exception as e:
                print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                retry_count += 1
                if retry_count < max_retries:
                    print(f"ğŸ”„ {retry_count * 2}ç§’å¾Œã«å†è©¦è¡Œ...")
                    await asyncio.sleep(retry_count * 2)
                else:
                    break
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        stream.stop_stream()
        stream.close()
        self.audio.terminate()
        print("ğŸ¤ éŸ³å£°éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã—ãŸ")

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
async def run_server():
    """ã‚µãƒ¼ãƒãƒ¼èµ·å‹•"""
    import uvicorn
    config = uvicorn.Config(app, host="0.0.0.0", port=8003, log_level="info")
    server = uvicorn.Server(config)
    try:
        await server.serve()
    finally:
        voice_system.close_serial()

async def run_client():
    """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆèµ·å‹•"""
    await asyncio.sleep(2)  # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•å¾…æ©Ÿ
    client = VoiceClient()
    await client.start_recording()

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "client":
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚·ãƒªã‚¢ãƒ«é€šä¿¡ãªã—ï¼‰
        print("ğŸ¤ éŸ³å£°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆèµ·å‹•")
        print("â€» AtomS3åˆ¶å¾¡ã¯ã‚µãƒ¼ãƒãƒ¼å´ã§å®Ÿè¡Œã•ã‚Œã¾ã™")
        try:
            asyncio.run(VoiceClient().start_recording())
        except KeyboardInterrupt:
            print("çµ‚äº†")
    else:
        # ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆAtomS3åˆ¶å¾¡ã‚ã‚Šï¼‰
        print("ğŸš€ éŸ³å£°å¯¾è©±ã‚µãƒ¼ãƒãƒ¼èµ·å‹•")
        print("AtomS3ãŒCOM3ã«æ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        print("åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ 'python ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«å.py client' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        try:
            asyncio.run(run_server())
        except KeyboardInterrupt:
            print("ã‚µãƒ¼ãƒãƒ¼çµ‚äº†")
        finally:
            voice_system.close_serial()